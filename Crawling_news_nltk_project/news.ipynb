{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:05<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_글로벌 경제.csv 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:04<00:00, 70.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_부동산.csv 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 344/344 [00:04<00:00, 85.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_금융.csv 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:03<00:00, 76.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_증권.csv 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 형태소 분석기 및 불용어 정의\n",
    "komoran = Komoran()\n",
    "stopwords = ['의', '가', '이', '은', '는', '을', '를', '에', '와', '과', '으로', \n",
    "             '에서', '도', '합니다', '했다', '있습니다', '위해', '대해', '더']\n",
    "\n",
    "# 2. 특수문자 제거, 영어 제거, 공백 제거 후 형태소 분석 및 어간 추출하는 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 특수문자 제거\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # 영어 제거\n",
    "    text = re.sub(r'[a-zA-Z]', '', text)\n",
    "    \n",
    "    # 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 형태소 분석 및 어간 추출\n",
    "    tokens = komoran.morphs(text)\n",
    "    \n",
    "    # 불용어 제거\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "    \n",
    "    # 빈 토큰 제거\n",
    "    tokens = [token for token in tokens if token.strip() != '']\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# 3. 각 파일에 대해 처리할 함수 정의\n",
    "def process_file(input_file, category):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # 전처리 진행 (본문에 대해서만)\n",
    "    tqdm.pandas()  # 프로세스 진행 상태를 보기 위해 tqdm 적용\n",
    "    df['processed_content'] = df['content'].progress_apply(preprocess_text)\n",
    "    \n",
    "    # 카테고리 추가\n",
    "    df['category'] = category\n",
    "    \n",
    "    # 불필요한 열 제거 및 정리\n",
    "    df = df[['title', 'description', 'processed_content', 'category']]\n",
    "    \n",
    "    # 결과를 CSV 파일로 저장\n",
    "    output_file = f'processed_{category}.csv'\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f'{output_file} 저장 완료')\n",
    "\n",
    "# 4. 각 파일별로 처리\n",
    "process_file('글로벌 경제_naver_news.csv', '글로벌 경제')\n",
    "process_file('부동산_naver_news.csv', '부동산')\n",
    "process_file('금융_naver_news.csv', '금융')\n",
    "process_file('증권_naver_news.csv', '증권')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>윤석열 대통령-이시바 총리 첫 정상회담 &amp;quot;한·일관계 발전 계속 이어가...</td>\n",
       "      <td>홍보수석·박춘섭 &lt;b&gt;경제&lt;/b&gt;수석·이충면 외교비서관·김동배 외교부 아세안국장.....</td>\n",
       "      <td>홍보 수석 박 추 ㄴ 섭 수석 이충 면 외교 비서관 김 동 배 외교부 아세안 국장 ...</td>\n",
       "      <td>글로벌 경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(완)원전부터 신재생에너지까지···'기회의 땅' 동남아에 투자 잇는 韓...</td>\n",
       "      <td>싱가포르는 2050년까지 탄소 배출량 '0'을 달성하기 위한 국가 수소 전략을 수립...</td>\n",
       "      <td>싱가포르 까지 탄소 배출량 달성 하 기 위하 ㄴ 국가 수소 전략 수립 하 며 수소 ...</td>\n",
       "      <td>글로벌 경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[생활&lt;b&gt;경제&lt;/b&gt; 이슈] 본죽·본죽&amp;amp;비빔밥, ‘본프렌즈’ 발대식 진행 外</td>\n",
       "      <td>협회는 웹툰 산업의 지속 성장과 &lt;b&gt;글로벌&lt;/b&gt; 발전을 위해 큰 기여를 해 온 ...</td>\n",
       "      <td>협회 웹툰 산업 지속 성장 발전 위하 아 크 ㄴ 기여 하 아 오 ㄴ 네이버 웹툰 카...</td>\n",
       "      <td>글로벌 경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&amp;quot;한국의 한강&amp;quot;…K문학 노벨 문학상 거머쥐다</td>\n",
       "      <td>문화의 &lt;b&gt;글로벌&lt;/b&gt; 영향력이 커지고 있음을 나타낸다&amp;quot;고 전했습니다....</td>\n",
       "      <td>문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 습니다 한강 전라남도 광주 문인...</td>\n",
       "      <td>글로벌 경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K문학 &amp;quot;한국의 한강&amp;quot;, 노벨 문학상 거머줘...한림원 &amp;quot...</td>\n",
       "      <td>문화의 &lt;b&gt;글로벌&lt;/b&gt; 영향력이 커지고 있음을 나타낸다&amp;quot;고 전했다. &amp;...</td>\n",
       "      <td>문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 다 한국 한강 문학 노벨 문학상...</td>\n",
       "      <td>글로벌 경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>'매각 초시계' MG손보, 메리츠화재의 속내는</td>\n",
       "      <td>또 후순위채 혹은 신종자본&lt;b&gt;증권&lt;/b&gt; 등과 같은 부채에 대해서는 상환 의무가 ...</td>\n",
       "      <td>또 후순위채 혹은 신종 자본 증권 같 부채 대하 아서 상환 의무 없 다 다만 계약자...</td>\n",
       "      <td>증권</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>'강남 비-사이드', 기대 포인트 전격 공개</td>\n",
       "      <td>2024년 하반기를 뒤흔들 강렬한 추격 범죄 드라마의 탄생을 예고하며 폭발적인 반응...</td>\n",
       "      <td>하반기 뒤흔들 ㄹ 강렬 하 ㄴ 추격 범죄 드라마 탄생 예고 하 며 폭발 적 ㄴ 반응...</td>\n",
       "      <td>증권</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>대구광역시, '제3회 스타트업 오픈이노베이션 밋업' 개최... 15개 대중견...</td>\n",
       "      <td>삼성중공업, SK에너지, 호반건설, DGB금융그룹, 하나&lt;b&gt;증권&lt;/b&gt;, 교보생명...</td>\n",
       "      <td>삼성중공업 에너지 호반건설 금융 그룹 증권 교보생명보험 대동 삼보 모터스 삼 익 카...</td>\n",
       "      <td>증권</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>사이냅소프트, &lt;b&gt;증권&lt;/b&gt;신고서 제출…코스닥 시장 상장 절차 돌입</td>\n",
       "      <td>인공지능 디지털 문서 SaaS 기업 사이냅소프트(대표이사 전경헌)가 &lt;b&gt;증권&lt;/b...</td>\n",
       "      <td>인공지능 디지털 문서 기업 사이냅소프트대표이사 전경 허 ㄴ가 증권 신고서 제출 하 ...</td>\n",
       "      <td>증권</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>코스피, 반도체주 강세에도 2590대 마감</td>\n",
       "      <td>지수는 17.29p(0.67%) 오른 2611.65로 출발한 뒤 오름폭을 점차 줄이...</td>\n",
       "      <td>지수 오르 ㄴ 출발 하 ㄴ 뒤 오름 폭 점차 줄이 면서 대 내주 었 다 유가증권 시...</td>\n",
       "      <td>증권</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0        윤석열 대통령-이시바 총리 첫 정상회담 &quot;한·일관계 발전 계속 이어가...   \n",
       "1            (완)원전부터 신재생에너지까지···'기회의 땅' 동남아에 투자 잇는 韓...   \n",
       "2       [생활<b>경제</b> 이슈] 본죽·본죽&amp;비빔밥, ‘본프렌즈’ 발대식 진행 外   \n",
       "3                    &quot;한국의 한강&quot;…K문학 노벨 문학상 거머쥐다   \n",
       "4     K문학 &quot;한국의 한강&quot;, 노벨 문학상 거머줘...한림원 &quot...   \n",
       "...                                                 ...   \n",
       "1138                          '매각 초시계' MG손보, 메리츠화재의 속내는   \n",
       "1139                           '강남 비-사이드', 기대 포인트 전격 공개   \n",
       "1140      대구광역시, '제3회 스타트업 오픈이노베이션 밋업' 개최... 15개 대중견...   \n",
       "1141            사이냅소프트, <b>증권</b>신고서 제출…코스닥 시장 상장 절차 돌입   \n",
       "1142                            코스피, 반도체주 강세에도 2590대 마감   \n",
       "\n",
       "                                            description  \\\n",
       "0     홍보수석·박춘섭 <b>경제</b>수석·이충면 외교비서관·김동배 외교부 아세안국장.....   \n",
       "1     싱가포르는 2050년까지 탄소 배출량 '0'을 달성하기 위한 국가 수소 전략을 수립...   \n",
       "2     협회는 웹툰 산업의 지속 성장과 <b>글로벌</b> 발전을 위해 큰 기여를 해 온 ...   \n",
       "3     문화의 <b>글로벌</b> 영향력이 커지고 있음을 나타낸다&quot;고 전했습니다....   \n",
       "4     문화의 <b>글로벌</b> 영향력이 커지고 있음을 나타낸다&quot;고 전했다. &...   \n",
       "...                                                 ...   \n",
       "1138  또 후순위채 혹은 신종자본<b>증권</b> 등과 같은 부채에 대해서는 상환 의무가 ...   \n",
       "1139  2024년 하반기를 뒤흔들 강렬한 추격 범죄 드라마의 탄생을 예고하며 폭발적인 반응...   \n",
       "1140  삼성중공업, SK에너지, 호반건설, DGB금융그룹, 하나<b>증권</b>, 교보생명...   \n",
       "1141  인공지능 디지털 문서 SaaS 기업 사이냅소프트(대표이사 전경헌)가 <b>증권</b...   \n",
       "1142  지수는 17.29p(0.67%) 오른 2611.65로 출발한 뒤 오름폭을 점차 줄이...   \n",
       "\n",
       "                                      processed_content category  \n",
       "0     홍보 수석 박 추 ㄴ 섭 수석 이충 면 외교 비서관 김 동 배 외교부 아세안 국장 ...   글로벌 경제  \n",
       "1     싱가포르 까지 탄소 배출량 달성 하 기 위하 ㄴ 국가 수소 전략 수립 하 며 수소 ...   글로벌 경제  \n",
       "2     협회 웹툰 산업 지속 성장 발전 위하 아 크 ㄴ 기여 하 아 오 ㄴ 네이버 웹툰 카...   글로벌 경제  \n",
       "3     문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 습니다 한강 전라남도 광주 문인...   글로벌 경제  \n",
       "4     문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 다 한국 한강 문학 노벨 문학상...   글로벌 경제  \n",
       "...                                                 ...      ...  \n",
       "1138  또 후순위채 혹은 신종 자본 증권 같 부채 대하 아서 상환 의무 없 다 다만 계약자...       증권  \n",
       "1139  하반기 뒤흔들 ㄹ 강렬 하 ㄴ 추격 범죄 드라마 탄생 예고 하 며 폭발 적 ㄴ 반응...       증권  \n",
       "1140  삼성중공업 에너지 호반건설 금융 그룹 증권 교보생명보험 대동 삼보 모터스 삼 익 카...       증권  \n",
       "1141  인공지능 디지털 문서 기업 사이냅소프트대표이사 전경 허 ㄴ가 증권 신고서 제출 하 ...       증권  \n",
       "1142  지수 오르 ㄴ 출발 하 ㄴ 뒤 오름 폭 점차 줄이 면서 대 내주 었 다 유가증권 시...       증권  \n",
       "\n",
       "[1143 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = 'processed_combined_news.csv'\n",
    "df=pd.read_csv(FILE)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>encoded_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>홍보 수석 박 추 ㄴ 섭 수석 이충 면 외교 비서관 김 동 배 외교부 아세안 국장 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르 까지 탄소 배출량 달성 하 기 위하 ㄴ 국가 수소 전략 수립 하 며 수소 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>협회 웹툰 산업 지속 성장 발전 위하 아 크 ㄴ 기여 하 아 오 ㄴ 네이버 웹툰 카...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 습니다 한강 전라남도 광주 문인...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 다 한국 한강 문학 노벨 문학상...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>또 후순위채 혹은 신종 자본 증권 같 부채 대하 아서 상환 의무 없 다 다만 계약자...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>하반기 뒤흔들 ㄹ 강렬 하 ㄴ 추격 범죄 드라마 탄생 예고 하 며 폭발 적 ㄴ 반응...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>삼성중공업 에너지 호반건설 금융 그룹 증권 교보생명보험 대동 삼보 모터스 삼 익 카...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>인공지능 디지털 문서 기업 사이냅소프트대표이사 전경 허 ㄴ가 증권 신고서 제출 하 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>지수 오르 ㄴ 출발 하 ㄴ 뒤 오름 폭 점차 줄이 면서 대 내주 었 다 유가증권 시...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_content  encoded_category\n",
       "0     홍보 수석 박 추 ㄴ 섭 수석 이충 면 외교 비서관 김 동 배 외교부 아세안 국장 ...                 0\n",
       "1     싱가포르 까지 탄소 배출량 달성 하 기 위하 ㄴ 국가 수소 전략 수립 하 며 수소 ...                 0\n",
       "2     협회 웹툰 산업 지속 성장 발전 위하 아 크 ㄴ 기여 하 아 오 ㄴ 네이버 웹툰 카...                 0\n",
       "3     문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 습니다 한강 전라남도 광주 문인...                 0\n",
       "4     문화 영향력 커지 고 있 음 나타내 ㄴ다고 전하 았 다 한국 한강 문학 노벨 문학상...                 0\n",
       "...                                                 ...               ...\n",
       "1138  또 후순위채 혹은 신종 자본 증권 같 부채 대하 아서 상환 의무 없 다 다만 계약자...                 3\n",
       "1139  하반기 뒤흔들 ㄹ 강렬 하 ㄴ 추격 범죄 드라마 탄생 예고 하 며 폭발 적 ㄴ 반응...                 3\n",
       "1140  삼성중공업 에너지 호반건설 금융 그룹 증권 교보생명보험 대동 삼보 모터스 삼 익 카...                 3\n",
       "1141  인공지능 디지털 문서 기업 사이냅소프트대표이사 전경 허 ㄴ가 증권 신고서 제출 하 ...                 3\n",
       "1142  지수 오르 ㄴ 출발 하 ㄴ 뒤 오름 폭 점차 줄이 면서 대 내주 었 다 유가증권 시...                 3\n",
       "\n",
       "[1143 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "# 데이터 로드 (이미 CSV로 데이터가 주어졌으므로 이를 로드함)\n",
    "df = pd.read_csv('processed_combined_news.csv')\n",
    "\n",
    "# 텍스트 전처리 함수 정의\n",
    "def clean_text(text):\n",
    "    # 여러 공백을 하나로 대체\n",
    "    text = re.sub(r'\\s+', ' ', text)  # 여러 공백을 하나로\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "    return text.strip()\n",
    "\n",
    "# 'processed_content' 열에 전처리 적용\n",
    "df['cleaned_content'] = df['processed_content'].apply(clean_text)\n",
    "\n",
    "# 'category' 열에 대해 Label Encoding 적용\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_category'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# 결과 데이터셋을 필요한 열만 추출\n",
    "cleaned_df = df[['cleaned_content', 'encoded_category']]\n",
    "\n",
    "# 전처리된 데이터를 임베딩이나 모델 학습에 사용할 수 있도록 준비됨\n",
    "\n",
    "cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-26\\anaconda3\\envs\\TEXT_018_230_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\KDP-26\\anaconda3\\envs\\TEXT_018_230_38\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 92/92 [03:30<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3832044536652772, Val Loss: 1.3748200406198916, Val Accuracy: 0.3624454148471616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:36<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.3795768605626149, Val Loss: 1.3678138204242871, Val Accuracy: 0.3624454148471616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:47<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.3784881065721097, Val Loss: 1.3686953420224397, Val Accuracy: 0.3624454148471616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.3777879567249962, Val Loss: 1.3647855883059294, Val Accuracy: 0.36681222707423583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1.3749126597591068, Val Loss: 1.360627682312675, Val Accuracy: 0.39737991266375544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:48<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1.369503898465115, Val Loss: 1.3539793543193652, Val Accuracy: 0.37117903930131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:45<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 1.3630878329277039, Val Loss: 1.336759240730949, Val Accuracy: 0.4017467248908297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.3428218533163485, Val Loss: 1.2891635687454888, Val Accuracy: 0.4192139737991266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 1.3246563906254976, Val Loss: 1.2290177915407263, Val Accuracy: 0.4890829694323144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1.2441415708997976, Val Loss: 1.1486926830333213, Val Accuracy: 0.5021834061135371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 1.167899718751078, Val Loss: 1.1231999682343525, Val Accuracy: 0.4890829694323144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:49<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 1.1517684323632198, Val Loss: 1.0570003727208013, Val Accuracy: 0.5502183406113537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 1.083946520867555, Val Loss: 1.0369812716608462, Val Accuracy: 0.5502183406113537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:42<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 1.1495807980713637, Val Loss: 0.9364138556563336, Val Accuracy: 0.6331877729257642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 1.0467596352100372, Val Loss: 0.8979478659837142, Val Accuracy: 0.6506550218340611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 1.0594992870869844, Val Loss: 0.9149872349656146, Val Accuracy: 0.6419213973799127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 1.0199405745319698, Val Loss: 0.8402800559997559, Val Accuracy: 0.6899563318777293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.9543305408695469, Val Loss: 0.8765037318934565, Val Accuracy: 0.6681222707423581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:44<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.942884997829147, Val Loss: 0.985665051833443, Val Accuracy: 0.5938864628820961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.8968541567092356, Val Loss: 0.7204434249712073, Val Accuracy: 0.7467248908296943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:50<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.8949553801313691, Val Loss: 1.0187306015387825, Val Accuracy: 0.62882096069869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.90218033220457, Val Loss: 0.7410927920237832, Val Accuracy: 0.7161572052401747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:53<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.8841243266411449, Val Loss: 0.9563321237978728, Val Accuracy: 0.6419213973799127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:38<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.8501915542975716, Val Loss: 0.7774419421735017, Val Accuracy: 0.6986899563318777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:49<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.8261517697702283, Val Loss: 0.7523206925910452, Val Accuracy: 0.7205240174672489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:38<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.9068236904947654, Val Loss: 0.7847777734632078, Val Accuracy: 0.6768558951965066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:45<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.8553036820629368, Val Loss: 0.8044244698856188, Val Accuracy: 0.7117903930131004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.7895229193179504, Val Loss: 0.7263989655867867, Val Accuracy: 0.7510917030567685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.7592168706266776, Val Loss: 0.7888695027517236, Val Accuracy: 0.7117903930131004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:38<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 0.819457933306694, Val Loss: 0.690642412589944, Val Accuracy: 0.7467248908296943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train Loss: 0.804147908868997, Val Loss: 0.6307372424913489, Val Accuracy: 0.7860262008733624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 0.827839569553085, Val Loss: 0.6482972463835841, Val Accuracy: 0.7467248908296943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train Loss: 0.733282041290532, Val Loss: 0.9328487981920657, Val Accuracy: 0.6812227074235808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train Loss: 0.7493855247031087, Val Loss: 0.8331541114527247, Val Accuracy: 0.7074235807860262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:44<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train Loss: 0.7982390037049418, Val Loss: 0.6199723728325056, Val Accuracy: 0.7729257641921398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 0.7098450388597406, Val Loss: 0.6525549370309581, Val Accuracy: 0.777292576419214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:44<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train Loss: 0.7120667083755784, Val Loss: 0.6746188752029253, Val Accuracy: 0.7903930131004366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:38<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train Loss: 0.7277132379619972, Val Loss: 0.7591848444679509, Val Accuracy: 0.7117903930131004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 0.6834156249204407, Val Loss: 0.7999039136845133, Val Accuracy: 0.7030567685589519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:40<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 0.6873852779035983, Val Loss: 0.7381575055744337, Val Accuracy: 0.7292576419213974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:45<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train Loss: 0.6941035930877146, Val Loss: 0.6696691461231398, Val Accuracy: 0.759825327510917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train Loss: 0.6999500215701435, Val Loss: 0.834469146054724, Val Accuracy: 0.7161572052401747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train Loss: 0.704803803368755, Val Loss: 0.8071815021660017, Val Accuracy: 0.7205240174672489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:47<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 0.6530062224230041, Val Loss: 0.6666656939879708, Val Accuracy: 0.759825327510917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Train Loss: 0.6041093330992304, Val Loss: 0.5405202495015186, Val Accuracy: 0.8165938864628821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:50<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train Loss: 0.6756106357535591, Val Loss: 0.6873861603114916, Val Accuracy: 0.7379912663755459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Train Loss: 0.7156047979774682, Val Loss: 0.6572864392529363, Val Accuracy: 0.74235807860262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:52<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 0.6411444980489172, Val Loss: 0.5542368798152261, Val Accuracy: 0.8209606986899564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:39<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Train Loss: 0.6056378634403581, Val Loss: 0.5827656180962272, Val Accuracy: 0.7860262008733624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:45<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6431141576689222, Val Loss: 0.7020497911650202, Val Accuracy: 0.7117903930131004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Train Loss: 0.6285093186990075, Val Loss: 0.49217080162919086, Val Accuracy: 0.8122270742358079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:44<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Train Loss: 0.6793576657124187, Val Loss: 0.543708310826965, Val Accuracy: 0.8209606986899564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:37<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Train Loss: 0.64149150673462, Val Loss: 0.5165635878625123, Val Accuracy: 0.8034934497816594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:41<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Train Loss: 0.6079520726495463, Val Loss: 0.637799410716347, Val Accuracy: 0.74235807860262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Train Loss: 0.6668055951595306, Val Loss: 0.5871779128261234, Val Accuracy: 0.7729257641921398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:47<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Train Loss: 0.6308153932509215, Val Loss: 0.6031506184650504, Val Accuracy: 0.7641921397379913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:44<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Train Loss: 0.5957346243540877, Val Loss: 0.5936072870441105, Val Accuracy: 0.7685589519650655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:48<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Train Loss: 0.5774170236419076, Val Loss: 0.6948128601779109, Val Accuracy: 0.7685589519650655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Train Loss: 0.5918130884351938, Val Loss: 0.5966636583856915, Val Accuracy: 0.7991266375545851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [03:48<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train Loss: 0.5762659809349672, Val Loss: 0.7718157975570016, Val Accuracy: 0.74235807860262\n",
      "Model saved to bert_lstm_model.pth\n",
      "Final Accuracy: 0.74235807860262\n",
      "Precision: 0.7812155031073027, Recall: 0.74235807860262, F1 Score: 0.7276588428786709\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel # 발트 모델 불러오기\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 데이터 준비 (전처리된 뉴스 텍스트와 레이블)\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # BERT 모델에 맞게 데이터셋을 추가 전처리\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 2. BERT + LSTM 모델 정의\n",
    "class BertLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, hidden_dim, output_dim, lstm_layers, bidirectional, dropout):\n",
    "        super(BertLSTMClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name) # 사전 학습된 BERT모델 로드\n",
    "        self.lstm = nn.LSTM(input_size=self.bert.config.hidden_size, # 레이어 정의\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout) # 과적합 방지\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad(): #BERT 출력\n",
    "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        sequence_output = bert_output.last_hidden_state  # BERT의 마지막 은닉 상태\n",
    "        lstm_output, _ = self.lstm(sequence_output)  # LSTM 레이어에 입력 은닉 상태 업데이트\n",
    "        lstm_output = self.dropout(lstm_output[:, -1, :])  # 마지막 타임스텝 출력 사용\n",
    "        logits = self.fc(lstm_output)\n",
    "        return logits\n",
    "\n",
    "# 3. 옵티마이저 및 손실 함수 정의\n",
    "def get_optimizer_and_loss_fn(model):\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    return optimizer, loss_fn\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, optimizer, loss_fn, device, epochs, patience):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, loss_fn, device)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader)}, Val Loss: {val_loss}, Val Accuracy: {val_acc}')\n",
    "\n",
    "        # 조기 종료 (Early Stopping)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"조기 종료!\")\n",
    "                break\n",
    "\n",
    "# 5. 평가 함수\n",
    "def evaluate_model(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 6. 성능 평가 (Precision, Recall, F1 Score)\n",
    "def calculate_metrics(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 7. 모델 저장 함수\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# 8. 모델 불러오기 함수\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()  # 평가 모드로 설정 (Dropout 등 비활성화)\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# 9. 데이터셋 준비 및 학습 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터셋 로드 (예시)\n",
    "    df = cleaned_df\n",
    "    texts = df['cleaned_content'].tolist()\n",
    "    labels = df['encoded_category'].tolist()\n",
    "\n",
    "    # Train / Validation Split\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # BERT Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "\n",
    "    # Dataset 생성\n",
    "    max_len = 128\n",
    "    train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_len)\n",
    "    val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_len)\n",
    "\n",
    "    # DataLoader\n",
    "    batch_size = 10\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 옵티마이저 및 손실 함수 정의\n",
    "    model = BertLSTMClassifier(\n",
    "        bert_model_name='monologg/koelectra-base-v3-discriminator',\n",
    "        hidden_dim=256,\n",
    "        output_dim=len(set(labels)),  # 카테고리 수만큼 output_dim 설정\n",
    "        lstm_layers=2,\n",
    "        bidirectional=True,\n",
    "        dropout=0.3\n",
    "    )\n",
    "\n",
    "    # 디바이스 설정 (GPU가 있으면 사용)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer, loss_fn = get_optimizer_and_loss_fn(model)\n",
    "\n",
    "    # 학습 실행\n",
    "    epochs = 60\n",
    "    patience = 10  # Early stopping patience\n",
    "    train_model(model, train_loader, val_loader, optimizer, loss_fn, device, epochs, patience)\n",
    "\n",
    "    # 학습 후 모델 저장\n",
    "    save_model(model, 'bert_lstm_model.pth')\n",
    "\n",
    "    # 평가 및 성능 출력\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 최종 성능 평가\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(all_predictions, all_true_labels)\n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEXT_018_230_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
